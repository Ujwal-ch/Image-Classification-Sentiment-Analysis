import os
import shutil
import zipfile

# Define paths
dataset_zip_path = "C:\\Users\\uchepyala1\\Downloads\\FINAL_419.zip"
extracted_folder_path = "C:\\Users\\uchepyala1\\Downloads\\DSCI_419"

# Extract the dataset
with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_folder_path)

# Define paths to the indoor images folder
indoor_images_folder = os.path.join(extracted_folder_path, "indoorCVPR_09")
# Define folders to remove
folders_to_remove = ['Laboratorywet', 'Laundromat', 'Library', 'Livingroom', 'Lobby', 'locker_room']

# Remove the folders
for folder in folders_to_remove:
    folder_path = os.path.join(indoor_images_folder, 'Images', folder)
    if os.path.exists(folder_path):
        shutil.rmtree(folder_path)
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from sklearn.model_selection import train_test_split

# Set device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Define transforms
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Load dataset
dataset = ImageFolder(os.path.join(indoor_images_folder, "Images"), transform=transform)

# Split dataset into train and test
train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)

# Define data loaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
#Now, let's define and train the baseline CNN model:
import torch.nn.functional as F
# Define baseline CNN model
class BaselineCNN(nn.Module):
    def __init__(self):
        super(BaselineCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc1 = nn.Linear(64 * 16 * 16, 512)
        self.fc2 = nn.Linear(512, 67)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 16 * 16)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Initialize model, loss function, and optimizer
baseline_model = BaselineCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)

# Train baseline model
for epoch in range(10):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()
        outputs = baseline_model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 99:    # print every 100 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 100))
            running_loss = 0.0

print('Finished Training of Baseline CNN')
[1,   100] loss: 3.706
[2,   100] loss: 2.985
[3,   100] loss: 2.433
[4,   100] loss: 1.768
[5,   100] loss: 0.888
[6,   100] loss: 0.292
[7,   100] loss: 0.081
[8,   100] loss: 0.048
[9,   100] loss: 0.025
[10,   100] loss: 0.023
Finished Training of Baseline CNN
# Evaluate baseline model
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = baseline_model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the baseline CNN model on the test images: %d %%' % (100 * correct / total))
Accuracy of the baseline CNN model on the test images: 26 %
# Second CNN model with data augmentation and dropout
class CNNWithDataAugAndDropout(nn.Module):
    def __init__(self):
        super(CNNWithDataAugAndDropout, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc1 = nn.Linear(64 * 16 * 16, 512)
        self.fc2 = nn.Linear(512, 67)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 16 * 16)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# Initialize model, loss function, and optimizer
model_with_aug_dropout = CNNWithDataAugAndDropout().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_with_aug_dropout.parameters(), lr=0.001)

# Train model
for epoch in range(10):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()
        outputs = model_with_aug_dropout(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 99:    # print every 100 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 100))
            running_loss = 0.0

print('Finished Training of CNN with Data Augmentation and Dropout')
[1,   100] loss: 3.805
[2,   100] loss: 3.303
[3,   100] loss: 2.927
[4,   100] loss: 2.620
[5,   100] loss: 2.245
[6,   100] loss: 1.870
[7,   100] loss: 1.478
[8,   100] loss: 1.106
[9,   100] loss: 0.810
[10,   100] loss: 0.596
Finished Training of CNN with Data Augmentation and Dropout
# Evaluate model
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = model_with_aug_dropout(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the CNN with Data Augmentation and Dropout model on the test images: %d %%' % (100 * correct / total))
Accuracy of the CNN with Data Augmentation and Dropout model on the test images: 22 %
# Third CNN model based on pre-trained model (transfer learning)
pretrained_resnet = torchvision.models.resnet18(pretrained=True)
pretrained_resnet.fc = nn.Linear(pretrained_resnet.fc.in_features, 67)

# Freeze pre-trained layers
for param in pretrained_resnet.parameters():
    param.requires_grad = False

# Initialize new layers
pretrained_model = pretrained_resnet.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(pretrained_model.fc.parameters(), lr=0.001)

# Freeze pre-trained layers
for param in pretrained_resnet.parameters():
    param.requires_grad = False

# Unfreeze the last layer for training
for param in pretrained_resnet.fc.parameters():
    param.requires_grad = True
# Train model
for epoch in range(5):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()
        outputs = pretrained_model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 99:    # print every 100 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 100))
            running_loss = 0.0

print('Finished Training of CNN based on Pre-trained Model')
[1,   100] loss: 3.709
[2,   100] loss: 2.812
[3,   100] loss: 2.490
[4,   100] loss: 2.344
[5,   100] loss: 2.235
Finished Training of CNN based on Pre-trained Model
# Evaluate model
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = pretrained_model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the CNN based on Pre-trained Model on the test images: %d %%' % (100 * correct / total))
Accuracy of the CNN based on Pre-trained Model on the test images: 27 %
Now, let's discuss which model to recommend for each question:
For the baseline CNN model, since it doesn't incorporate any advanced techniques like data augmentation or transfer learning, it's a good starting point to establish a performance baseline. This model can help you understand how more sophisticated models perform compared to a simple one.

For the second model with data augmentation and dropout, it's likely to perform better than the baseline CNN model as it includes techniques to reduce overfitting and enhance generalization. This model is recommended if computational resources allow for longer training times.

For the third model based on transfer learning, it might perform the best among the three, especially if the pre-trained model has been trained on a similar dataset or domain. Transfer learning leverages knowledge learned from a larger dataset and can be particularly beneficial when training data is limited. This model is recommended if computational resources are limited or if there's a need for faster training.

In summary, the recommendation depends on factors such as available computational resources, desired performance, and time constraints. If computational resources are limited, the third model based on transfer learning might be the best choice. Otherwise, if computational resources allow, the second model with data augmentation and dropout is likely to provide the best performance.

 
